{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning model building section: LogisticsRegression Model to predict delays due to an accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pyspark session creation and using pyspark and SQL functionality for data analysis\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# For performing pandas dataframe calculations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# machine learing MLIB libraries\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the spark session\n",
    "# use local[*] to use all the available core of the computer for processing\n",
    "sparkSession = SparkSession.builder.master(\"local[*]\").config(\"spark.driver.memory\",\"4g\")\\\n",
    "                        .appName(\"7082CEM_CourseWork_Sushil_ML_Section\")\\\n",
    "                        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the input data file( csv format, stored on local storage)\n",
    "accidents_df=sparkSession.read.csv(\"US_Accidents_June20.csv\",inferSchema=True,header=True)\n",
    "\n",
    "type(accidents_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the original dataframe just in case required \n",
    "orginal_df = accidents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the fields based on the initial assessment\n",
    "accidents_df=accidents_df.drop('ID','End_Lat','Start_Lat','Start_Lng','End_Lng','TMC','Number','Civil_Twilight',\\\n",
    "                               'Nautical_Twilight','Astronomical_Twilight',\\\n",
    "                               'Airport_Code','Country','Street','Zipcode','Weather_TimeStamp',\\\n",
    "                               'Side','Pressure(in)','Wind_Chill(F)','Precipitation(in)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_df=accidents_df.drop('Turning_Loop','Stop','Station','Roundabout','Railway','No_Exit','Give_Way',\\\n",
    "                              'Bump','Amenity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_df=accidents_df.drop('Description','Wind_Direction','Wind_Speed(mph)','Humidity(%)',\\\n",
    "                               'Temperature(F)','Traffic_Calming','Source','County')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate delays due an accident : based on accident start time and end time. Convert into minutes\n",
    "accidents_df= accidents_df.withColumn('durationAcc', (accidents_df['End_Time'].\\\n",
    "                                                  cast('long') - accidents_df['Start_Time'].cast('long'))/60)\n",
    "\n",
    "accidents_df = accidents_df.withColumn('durationAcc',accidents_df['durationAcc'].cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(training_data, test_data) = accidents_df.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Severity', 'int'),\n",
       " ('Start_Time', 'timestamp'),\n",
       " ('End_Time', 'timestamp'),\n",
       " ('Distance(mi)', 'double'),\n",
       " ('City', 'string'),\n",
       " ('State', 'string'),\n",
       " ('Timezone', 'string'),\n",
       " ('Visibility(mi)', 'double'),\n",
       " ('Weather_Condition', 'string'),\n",
       " ('Crossing', 'boolean'),\n",
       " ('Junction', 'boolean'),\n",
       " ('Traffic_Signal', 'boolean'),\n",
       " ('Sunrise_Sunset', 'string'),\n",
       " ('durationAcc', 'int')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find all the datatypes in dataset to decide on categorical features and continuous variable\n",
    "[i for i in accidents_df.dtypes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find null value count in data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agg = accidents_df.agg(*[count(when(isnull(c), c)).alias(c) for c in accidents_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Severity</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Start_Time</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>End_Time</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Distance(mi)</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timezone</th>\n",
       "      <td>3880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Visibility(mi)</th>\n",
       "      <td>75856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weather_Condition</th>\n",
       "      <td>76138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crossing</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Junction</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traffic_Signal</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunrise_Sunset</th>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>durationAcc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "Severity               0\n",
       "Start_Time             0\n",
       "End_Time               0\n",
       "Distance(mi)           0\n",
       "City                 112\n",
       "State                  0\n",
       "Timezone            3880\n",
       "Visibility(mi)     75856\n",
       "Weather_Condition  76138\n",
       "Crossing               0\n",
       "Junction               0\n",
       "Traffic_Signal         0\n",
       "Sunrise_Sunset       115\n",
       "durationAcc            0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_agg.toPandas().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3513617"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as the dataset has many rows so dropping rows with null value is not going to impact much. \n",
    "accidents_df=accidents_df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+------------+------------+-----+----------+--------------+-----------------+--------+--------+--------------+--------------+-----------+\n",
      "|Severity|         Start_Time|           End_Time|Distance(mi)|        City|State|  Timezone|Visibility(mi)|Weather_Condition|Crossing|Junction|Traffic_Signal|Sunrise_Sunset|durationAcc|\n",
      "+--------+-------------------+-------------------+------------+------------+-----+----------+--------------+-----------------+--------+--------+--------------+--------------+-----------+\n",
      "|       3|2016-02-08 05:46:00|2016-02-08 11:00:00|        0.01|      Dayton|   OH|US/Eastern|          10.0|       Light Rain|   false|   false|         false|         Night|        314|\n",
      "|       2|2016-02-08 06:07:59|2016-02-08 06:37:59|        0.01|Reynoldsburg|   OH|US/Eastern|          10.0|       Light Rain|   false|   false|         false|         Night|         30|\n",
      "|       2|2016-02-08 06:49:27|2016-02-08 07:19:27|        0.01|Williamsburg|   OH|US/Eastern|          10.0|         Overcast|   false|   false|          true|         Night|         30|\n",
      "|       3|2016-02-08 07:23:34|2016-02-08 07:53:34|        0.01|      Dayton|   OH|US/Eastern|           9.0|    Mostly Cloudy|   false|   false|         false|         Night|         30|\n",
      "|       2|2016-02-08 07:39:07|2016-02-08 08:09:07|        0.01|      Dayton|   OH|US/Eastern|           6.0|    Mostly Cloudy|   false|   false|          true|           Day|         30|\n",
      "+--------+-------------------+-------------------+------------+------------+-----+----------+--------------+-----------------+--------+--------+--------------+--------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accidents_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-calculate the null values after dropping rows with null value\n",
    "data_agg = accidents_df.agg(*[count(when(isnull(c), c)).alias(c) for c in accidents_df.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------+------------+----+-----+--------+--------------+-----------------+--------+--------+--------------+--------------+-----------+\n",
      "|Severity|Start_Time|End_Time|Distance(mi)|City|State|Timezone|Visibility(mi)|Weather_Condition|Crossing|Junction|Traffic_Signal|Sunrise_Sunset|durationAcc|\n",
      "+--------+----------+--------+------------+----+-----+--------+--------------+-----------------+--------+--------+--------------+--------------+-----------+\n",
      "|       0|         0|       0|           0|   0|    0|       0|             0|                0|       0|       0|             0|             0|          0|\n",
      "+--------+----------+--------+------------+----+-----+--------+--------------+-----------------+--------+--------+--------------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_agg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the original data into two parts : training data- for training the model, test_data - for testing the model\n",
    "(training_data, test_data) = accidents_df.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=training_data.withColumn('durationAcc',when(training_data['durationAcc'] < 0,0).\\\n",
    "                         otherwise(training_data['durationAcc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=training_data.withColumn('durationAcc',when(training_data['durationAcc'] >360,400).\\\n",
    "                         otherwise(training_data['durationAcc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|       durationAcc|\n",
      "+-------+------------------+\n",
      "|  count|           2745233|\n",
      "|   mean| 87.46776466696998|\n",
      "| stddev|104.73335456185325|\n",
      "|    min|                 0|\n",
      "|    max|               400|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.describe('durationAcc').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical features into numeric using Indexer and OneHotEncoderEstimatort\n",
    "stage1=StringIndexer(inputCol='City',outputCol='City_index',handleInvalid='keep',)\n",
    "stage2=StringIndexer(inputCol='State',outputCol='State_index',handleInvalid='keep',)\n",
    "stage3=StringIndexer(inputCol='Weather_Condition',outputCol='Weather_index',handleInvalid='keep',)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "OHE = OneHotEncoderEstimator(inputCols=['City_index', 'State_index','Weather_index'],\\\n",
    "                             outputCols=['City_OHE', 'State_OHE','Weather_OHE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble all the features which are used for model building into a single column\n",
    "stage_4 = VectorAssembler(inputCols=['Severity', 'City_OHE', 'State_OHE', 'Weather_OHE'],\n",
    "                          outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a logisticRegression model with input and output label column\n",
    "stage_5 = LogisticRegression(featuresCol='features',labelCol='durationAcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the pipeline with all the steps required for model building\n",
    "regression_pipeline = Pipeline(stages= [stage1, stage2, stage3,OHE, stage_4, stage_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model with training data\n",
    "model = regression_pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the trained model\n",
    "training_data_update = model.transform(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Severity: integer (nullable = true)\n",
      " |-- Start_Time: timestamp (nullable = true)\n",
      " |-- End_Time: timestamp (nullable = true)\n",
      " |-- Distance(mi): double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Timezone: string (nullable = true)\n",
      " |-- Visibility(mi): double (nullable = true)\n",
      " |-- Weather_Condition: string (nullable = true)\n",
      " |-- Crossing: boolean (nullable = true)\n",
      " |-- Junction: boolean (nullable = true)\n",
      " |-- Traffic_Signal: boolean (nullable = true)\n",
      " |-- Sunrise_Sunset: string (nullable = true)\n",
      " |-- durationAcc: integer (nullable = true)\n",
      " |-- City_index: double (nullable = false)\n",
      " |-- State_index: double (nullable = false)\n",
      " |-- Weather_index: double (nullable = false)\n",
      " |-- City_OHE: vector (nullable = true)\n",
      " |-- State_OHE: vector (nullable = true)\n",
      " |-- Weather_OHE: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data_update.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+-----------+\n",
      "|            features|       rawPrediction|         probability|prediction|durationAcc|\n",
      "+--------------------+--------------------+--------------------+----------+-----------+\n",
      "|(11569,[0,705,114...|[-1.8265070772726...|[1.18393016015430...|      29.0|         30|\n",
      "|(11569,[0,20,1140...|[-1.7579878772627...|[3.46421546727922...|      29.0|         63|\n",
      "|(11569,[0,139,114...|[-1.7666481526789...|[3.97320015397987...|      29.0|         60|\n",
      "|(11569,[0,170,114...|[-1.7663355860556...|[4.29333213253871...|      29.0|         30|\n",
      "|(11569,[0,302,114...|[-1.8190396701676...|[1.04387394954724...|      29.0|         45|\n",
      "|(11569,[0,140,114...|[-1.7726112401167...|[3.96603401395655...|      29.0|         90|\n",
      "|(11569,[0,610,114...|[-1.8334759817796...|[4.36694535432026...|      29.0|         30|\n",
      "|(11569,[0,633,114...|[-1.7327285346091...|[6.45200131241716...|     360.0|         30|\n",
      "|(11569,[0,35,1141...|[-1.8132216674745...|[2.92981488966075...|      29.0|         30|\n",
      "|(11569,[0,1641,11...|[-1.7547850144653...|[6.60721702738966...|     360.0|         30|\n",
      "+--------------------+--------------------+--------------------+----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the newly created columns like prediction and probability\n",
    "training_data_update.select('features','rawPrediction','probability','prediction','durationAcc').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the durationAcc from the test dataset\n",
    "# test_data=test_data.drop('durationAcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Severity: integer (nullable = true)\n",
      " |-- Start_Time: timestamp (nullable = true)\n",
      " |-- End_Time: timestamp (nullable = true)\n",
      " |-- Distance(mi): double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Timezone: string (nullable = true)\n",
      " |-- Visibility(mi): double (nullable = true)\n",
      " |-- Weather_Condition: string (nullable = true)\n",
      " |-- Crossing: boolean (nullable = true)\n",
      " |-- Junction: boolean (nullable = true)\n",
      " |-- Traffic_Signal: boolean (nullable = true)\n",
      " |-- Sunrise_Sunset: string (nullable = true)\n",
      " |-- durationAcc: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model using the test data\n",
    "predict = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Severity: integer (nullable = true)\n",
      " |-- Start_Time: timestamp (nullable = true)\n",
      " |-- End_Time: timestamp (nullable = true)\n",
      " |-- Distance(mi): double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Timezone: string (nullable = true)\n",
      " |-- Visibility(mi): double (nullable = true)\n",
      " |-- Weather_Condition: string (nullable = true)\n",
      " |-- Crossing: boolean (nullable = true)\n",
      " |-- Junction: boolean (nullable = true)\n",
      " |-- Traffic_Signal: boolean (nullable = true)\n",
      " |-- Sunrise_Sunset: string (nullable = true)\n",
      " |-- durationAcc: integer (nullable = true)\n",
      " |-- City_index: double (nullable = false)\n",
      " |-- State_index: double (nullable = false)\n",
      " |-- Weather_index: double (nullable = false)\n",
      " |-- City_OHE: vector (nullable = true)\n",
      " |-- State_OHE: vector (nullable = true)\n",
      " |-- Weather_OHE: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+------+------+--------+-----------------+-----------------+--------------+------------------+-----------------+-----------------+----------------+------------------+\n",
      "|summary|          Severity|       Distance(mi)|  City| State|Timezone|   Visibility(mi)|Weather_Condition|Sunrise_Sunset|       durationAcc|       City_index|      State_index|   Weather_index|        prediction|\n",
      "+-------+------------------+-------------------+------+------+--------+-----------------+-----------------+--------------+------------------+-----------------+-----------------+----------------+------------------+\n",
      "|  count|            684268|             684268|684268|684268|  684268|           684268|           684268|        684268|            684268|           684268|           684268|          684268|            684268|\n",
      "|   mean|2.3387576212828893|0.27849951626251285|  null|  null|    null|9.119851900132694|             null|          null|113.51050027182332|585.4898212396313|8.045569864439079|3.32836403280586|48.382465642116834|\n",
      "+-------+------------------+-------------------+------+------+--------+-----------------+-----------------+--------------+------------------+-----------------+-----------------+----------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict.describe().show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluatoion of the model\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol='durationAcc',\\\n",
    "                                                predictionCol='prediction',\\\n",
    "                                            metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluator.evaluate(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy =  0.34020149999707716\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy = ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
